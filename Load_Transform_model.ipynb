{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def clean_and_normalize_ML(df, columns_to_exclude=[]):\n",
        "    numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    non_numerical_features = df.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "    numerical_features_to_normalize = [col for col in numerical_features if col not in columns_to_exclude]\n",
        "\n",
        "    numerical_pipeline = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_pipeline, numerical_features_to_normalize)\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "\n",
        "    df_cleaned = preprocessor.fit_transform(df)\n",
        "\n",
        "    feature_names = numerical_features_to_normalize + non_numerical_features + columns_to_exclude\n",
        "\n",
        "    df_cleaned = pd.DataFrame(df_cleaned, columns=feature_names)\n",
        "\n",
        "    return df_cleaned\n",
        "\n",
        "df = pd.read_csv('energy.csv')\n",
        "columns_to_exclude = ['Year', 'Population']\n",
        "df_cleaned = clean_and_normalize(df, columns_to_exclude=columns_to_exclude)\n",
        "df_cleaned.to_csv('energy_cleaned.csv', index=False)\n"
      ],
      "metadata": {
        "id": "x5Rgn9E1dyH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def normalize_to_3nf(df):\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "\n",
        "    normalized_tables = {}\n",
        "\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        normalized_tables[col] = pd.DataFrame(df[col].unique(), columns=[col])\n",
        "        normalized_tables[col]['id'] = normalized_tables[col].index + 1\n",
        "\n",
        "    for col, table in normalized_tables.items():\n",
        "        df = df.merge(table, on=col, how='left')\n",
        "        df.drop(columns=[col], inplace=True)\n",
        "        df.rename(columns={'id': f'{col}_id'}, inplace=True)\n",
        "\n",
        "\n",
        "    id_columns = [col for col in df.columns if col.endswith('_id')]\n",
        "    other_columns = [col for col in df.columns if not col.endswith('_id')]\n",
        "    df = df[id_columns + other_columns]\n",
        "\n",
        "    normalized_tables['fact_table'] = df\n",
        "\n",
        "    return normalized_tables\n",
        "\n",
        "df = pd.read_csv('energy.csv')\n",
        "normalized_tables = normalize_to_3nf(df)\n",
        "\n",
        "for name, table in normalized_tables.items():\n",
        "    table.to_csv(f'tnf{name}.csv', index=False)"
      ],
      "metadata": {
        "id": "Rlh199N1jaxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtZMaw-zRWpD",
        "outputId": "b0342dd5-d37b-4330-9673-a30f3ece932d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data from temp.csv has been successfully written to temperatures table in climate.db.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "def csv_to_sqlite(csv_file, sqlite_db, table_name):\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    conn = sqlite3.connect(sqlite_db)\n",
        "\n",
        "    df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "\n",
        "    conn.close()\n",
        "    print(f\"Data from {csv_file} has been successfully written to {table_name} table in {sqlite_db}.\")\n",
        "\n",
        "csv_file = 'temp.csv'\n",
        "sqlite_db = 'climate.db'\n",
        "table_name = 'temperatures'\n",
        "\n",
        "csv_to_sqlite(csv_file, sqlite_db, table_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_role = '''Write python code to select relevant data and draw the chart. Use the SQL query provided to connect to the Database and retrieve data. The database name is chinook.db. Please create a data frame from relevant data and print the dataframe. Only use the sql i provide and do not generate your own. create a function called return_df() to return the df. '''"
      ],
      "metadata": {
        "id": "fCvq4Qt0SHXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_original = \"Find the percentage change in average temperature per country\"\n",
        "max_tokens = 2500"
      ],
      "metadata": {
        "id": "1tdSbHrhSSPF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}